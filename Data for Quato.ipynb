{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Quato data\n",
    "\n",
    "`csv file` containing filename entries, folders and other metadata\n",
    "\n",
    "We start by loading this file:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "df = pd.read_csv('data/largeDoseOfTurbiniumForQuato_reduced.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### show first few lines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Features\n",
    "\n",
    "file directory\n",
    "\n",
    "### Labels\n",
    "\n",
    "date_logged\tlog_name\tcontractor\tdata_type\tlog_service\tlog_activity\tlog_type\tlog_job\tlog_run\tlog_pass\tcasing_size_manual\tsection_size\tstation_number\tstation_depth\tmfc_correction\tinterpretation_number\tdate_stamp"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Clean and rename columns for clarity sake"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "COLUMN_MAPPING = {\n",
    "        'directory': 'file_directory',\n",
    "        'file': 'filename',\n",
    "        'contractor': 'company',\n",
    "        'log_service': 'service',\n",
    "        'log_activity': 'activity',\n",
    "    }\n",
    "df.columns = [col.strip() for col in df.columns]\n",
    " # column names have lots of surrounding whitepaces\n",
    "df.columns = [col.strip() for col in df.columns]\n",
    "\n",
    "# Ensure every string is stripped of random whitepaces.\n",
    "df = df.applymap(lambda val: val.strip() if hasattr(val, 'strip') else val)\n",
    "\n",
    "# Rename columns\n",
    "df = df.rename(columns=COLUMN_MAPPING)\n",
    "\n",
    "# Fill remaining NaNs with empty target\n",
    "df = df.fillna(value='')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test and train data split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "train, test = train_test_split(df, test_size=0.2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Join filename and filedirectory into a single string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#a new dataframe with just the feature data\n",
    "X_train = pd.DataFrame()\n",
    "X_test = pd.DataFrame()\n",
    "X_train['filename'] = train.apply(lambda line: os.path.join(line['file_directory'], line['filename']), axis=1)\n",
    "X_test['filename'] = test.apply(lambda line: os.path.join(line['file_directory'], line['filename']), axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get company as label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train =train['company'].astype(str)\n",
    "y_test = test['company'].astype(str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(X_train.head(), y_train.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Process filename inputs (for both train and test data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#split filename into independent chunks\n",
    "def file_path_formatter(string):\n",
    "        string = string.replace('_', ' ').replace('-', ' ').replace('.', ' ').replace(',', ' ').replace('/', ' ')\n",
    "        return string\n",
    "\n",
    "X_train['filename'] = X_train['filename'].apply(file_path_formatter)\n",
    "X_test['filename'] = X_test['filename'].apply(file_path_formatter)\n",
    "X.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Extract features using CountVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "count_vectorizer = CountVectorizer(ngram_range=(1, 2), \n",
    "                                    lowercase=True,\n",
    "                                    analyzer='word')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# creates the document term matrix\n",
    "count_train = count_vectorizer.fit_transform(X_train['filename'])\n",
    "count_test = count_vectorizer.transform(X_test['filename'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define ML model that currently is RandomForest as it perform the best"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "# Parameters for the model\n",
    "max_depth=None\n",
    "n_estimators=82\n",
    "min_samples_split=10\n",
    "max_features='sqrt'\n",
    "rf_classifier = RandomForestClassifier(max_depth=None, \n",
    "                                       n_jobs=-1,\n",
    "                                       n_estimators=n_estimators,\n",
    "                                       min_samples_split=min_samples_split,\n",
    "                                       max_features=max_features)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train ...."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(count_train.shape)\n",
    "rf_classifier.fit(count_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Predict on test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred = rf_classifier.predict(count_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Show some results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    " pd.options.display.max_colwidth = 300\n",
    "print(test['filename'][:3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(pred[:3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(test['company'][:3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
